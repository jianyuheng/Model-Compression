# Model-Compression
Technology of Model-Compression.

## [Introduction](https://cloud.tencent.com/developer/article/1005738)

## 知乎

- [Deep Compression （ICLR2016 Best Paper）](https://zhuanlan.zhihu.com/p/21574328)
- [模型压缩那些事](https://zhuanlan.zhihu.com/p/28439056)
- [当前深度神经网络模型压缩和加速都有哪些方法？](https://zhuanlan.zhihu.com/p/36051603)
- [NIPS 2017 网络压缩与加速 总结](https://zhuanlan.zhihu.com/p/31891903)
- [VALSE 2018年度进展报告 | 深度神经网络加速与压缩](https://zhuanlan.zhihu.com/p/36616989)
- [纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception](https://www.jiqizhixin.com/articles/2018-01-08-6)
- [CVPR 2018 高效小网络探密](https://zhuanlan.zhihu.com/p/37074222)

## Papers & Code

## model-compression-and-acceleration

### REFERENCE

- Acceleration and Model Compression

### 🌟 Overview

- [2018-arXiv] Recent Advances in Efficient Computation of Deep Convolutional Neural Networkspaper
- [2018-arXiv] A Survey on Acceleration of Deep Convolutional Neural Networkspaper
- [2017-arXiv] A Survey of Model Compression and Acceleration for Deep Neural Networks paper

- [2017-arXiv] Model compression as constrained optimization, with application to neural nets. Part I: general framework paper
- [2017-arXiv] Model compression as constrained optimization, with application to neural nets. Part II: quantizationpaper

### 🌟 Compact Network Design

- [2018-CVPR] IGCV2: Interleaved Structured Sparse Convolutional Neural Networks paper
- [2018-arXiv] SqueezeNext: Hardware-Aware Neural Network Design  paper code
- [2018-arXiv] IGCV3: Interleaved Low-Rank Group Convolutions for Efficient Deep Neural Networks paper
- [2018-CVPR] MobileNetV2: Inverted Residuals and Linear Bottlenecks papercode
- [2017-CVPR] SENet: Squeeze-and-Excitation Networkspaper code
- [2017-CVPR] MobileNetsV1: Efficient Convolutional Neural Networks for Mobile Vision Applicationspaper code
- [2017-CVPR] ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devicespaper code
- [2017-CVPR] ResNeXt: Aggregated Residual Transformations for Deep Neural Networks paper code
- [2017-CVPR] Xception: Deep Learning with Depthwise Separable Convolutions paper code
- [2017-ICCV] ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression paper code
- [2017-CVPR] SEP-Nets: Small and Effective Pattern Networks paper 

- [2016-ICLR] SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and < 0.5MB model size paper code

### 🌟 Distillation

- [2018-ICLR]  Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracypaper 

- [2018-ICLR] Model compression via distillation and quantization paper 
- [2018-AAAI] DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transferpaper
- [2017-CVPR] Like What You Like: Knowledge Distill via Neuron Selectivity Transfer paper
- [2017-CVPR] A Gift from Knowledge Distillation:Fast Optimization, Network Minimization and Transfer Learningpaper

- [2016-CVPR] Cross Model Distillation for Supervision Transfer paper code
- [2016-ICLR] Net2net: Accelerating learning via knowledge transferpaper

- [2015-ICLR] FitNets: Hints for Thin Deep Nets paper 

### 🌟 Pruning

- [2018-ICLR] To prune, or not to prune: exploring the efficacy of pruning for model compression paper 
- [2018-CVPR] NISP: Pruning Networks using Neuron Importance Score Propagation paper 
- [2018-CVPR] “Learning-Compression” Algorithms for Neural Net Pruning paper
- [2018-ICLR]Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers paper 
- [2018-ICLR] Efficient Sparse-Winograd Convolutional Neural Networks  paper 

- [2017-ICCV] Channel Pruning for Accelerating Very Deep Neural Networks paper code

- [2018-WACV] Recovering from Random Pruning: On the Plasticity of Deep Convolutional Neural Networks  paper 
- [2018-ICML] Deep k-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions paper code

### 🌟 Binarization

- [2016-ArXiv] Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1 paper code
- [2016-ECCV] XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks paper code

### 🌟 Quantization

- [2018-ICLR]  Variational Network Quantizationpaper 
- [2018-AAAI] Deep Neural Network Compression with Single and Multiple Level Quantization paper
- [2018-CVPR] Google: Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference paper 
- [2018-ArXiv] Google: Quantizing deep convolutional networks for efficient inference: A whitepaperpaper
- [2018-ICLR] Training and Inference with Integers in Deep Neural Networks paper
- [2018-arXiv] On the Universal Approximability of Quantized ReLU Neural Networks paper 

### 🌟 Low Rank Approximation



### 🌟 Accelerating / Fast Algorithms

- [2018-AAAI] Learning a Wavelet-like Auto-Encoder to Accelerate Deep Neural Networks paper
- [2018-arXiv] Uber SBNet: Sparse Blocks Network for Fast Inferencepaper












